{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d9cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe7e8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\TempAccess\\\\Documents\\\\Dhruv\\\\RAG\\\\context_enrichment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49ec6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\TempAccess\\\\Documents\\\\Dhruv\\\\RAG'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\TempAccess\\Documents\\Dhruv\\RAG\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c75d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_function_openai import (\n",
    "    Document,\n",
    "    RetrievalResult,\n",
    "    OpenAIEmbedder,\n",
    "    FAISSVectorStore,\n",
    "    OpenAIChat,\n",
    "    read_pdf,\n",
    "    chunk_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c05a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkStore:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._chunks: List[str] = []\n",
    "        self._doc_id: str = \"\"\n",
    "\n",
    "    def add_chunks(self, chunks: List[str], doc_id: str = \"doc_0\") -> None:\n",
    "        \"\"\"\n",
    "        Store all chunks in order.\n",
    "\n",
    "        Args:\n",
    "            chunks:  List of chunk texts, in document order.\n",
    "            doc_id:  Source document identifier.\n",
    "        \"\"\"\n",
    "        self._chunks = chunks\n",
    "        self._doc_id = doc_id\n",
    "\n",
    "    def get(self, index: int) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Retrieve a chunk by its position index. O(1) lookup.\n",
    "\n",
    "        Args:\n",
    "            index:  Chunk position (0-based).\n",
    "\n",
    "        Returns:\n",
    "            Chunk text, or None if index is out of range.\n",
    "        \"\"\"\n",
    "        if 0 <= index < len(self._chunks):\n",
    "            return self._chunks[index]\n",
    "        return None\n",
    "\n",
    "    def get_window(self, center: int, num_neighbors: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve a window of chunks centered on the given index.\n",
    "\n",
    "        Args:\n",
    "            center:         Index of the retrieved (relevant) chunk.\n",
    "            num_neighbors:  Number of chunks to include before and after.\n",
    "\n",
    "        Returns:\n",
    "            Ordered list of chunk texts in [center - N, center + N] range.\n",
    "        \"\"\"\n",
    "        start = max(0, center - num_neighbors)\n",
    "        end = min(len(self._chunks), center + num_neighbors + 1)\n",
    "        return [self._chunks[i] for i in range(start, end)]\n",
    "\n",
    "    @property\n",
    "    def total_chunks(self) -> int:\n",
    "        return len(self._chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec6e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEnrichmentRetriever:\n",
    "    \"\"\"\n",
    "    Retriever that expands each vector search hit with neighboring chunks.\n",
    "\n",
    "    Pipeline:\n",
    "        1. Chunk document with overlap ‚Üí store in FAISS + ChunkStore\n",
    "        2. Query ‚Üí vector search ‚Üí top-k chunk indices\n",
    "        3. For each hit, grab ¬±num_neighbors from ChunkStore\n",
    "        4. Concatenate, removing overlap to avoid text duplication\n",
    "        5. Return expanded context strings\n",
    "\n",
    "    Args:\n",
    "        embedding_model:  OpenAI embedding model name.\n",
    "        chunk_size:       Characters per chunk.\n",
    "        chunk_overlap:    Overlap between consecutive chunks.\n",
    "        num_neighbors:    How many chunks to pad before/after each hit.\n",
    "        k:                Number of top results from vector search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_model: str = \"text-embedding-3-small\",\n",
    "        chunk_size: int = 1000,\n",
    "        chunk_overlap: int = 200,\n",
    "        num_neighbors: int = 1,\n",
    "        k: int = 3,\n",
    "    ):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.k = k\n",
    "        self.embedder = OpenAIEmbedder(model=embedding_model)\n",
    "        self.vector_store = FAISSVectorStore(dimension=self.embedder.dimension)\n",
    "        self.chunk_store = ChunkStore()\n",
    "\n",
    "    \n",
    "    def index_document(self, text:str, doc_id:str=\"doc_0\")->int:\n",
    "        \"\"\"\n",
    "        Chunk and index a document into both FAISS and the ChunkStore.\n",
    "\n",
    "        Args:\n",
    "            text:    Full document text.\n",
    "            doc_id:  Document identifier.\n",
    "\n",
    "        Returns:\n",
    "            Number of chunks created.\n",
    "        \"\"\"\n",
    "        chunks = chunk_text(\n",
    "            text,\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap\n",
    "        )\n",
    "\n",
    "        self.chunk_store.add_chunks(chunks=chunks, doc_id=doc_id)\n",
    "\n",
    "        documents = []\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    content=chunk,\n",
    "                    metadata={\n",
    "                        \"doc_id\":doc_id,\n",
    "                        \"chunk_index\":i, \n",
    "                        \"total_chunks\":len(chunks)\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "        documents = self.embedder.embed_documents(documents)\n",
    "        \n",
    "        self.vector_store.add_documents(documents)\n",
    "\n",
    "        return len(chunks)\n",
    "\n",
    "\n",
    "    def index_pdf(self, file_path:str, doc_id:Optional[str]=None)->int:\n",
    "        \"\"\"\n",
    "        Read a PDF and index its contents.\n",
    "\n",
    "        Args:\n",
    "            file_path:  Path to PDF file.\n",
    "            doc_id:     Document ID (defaults to filename).\n",
    "\n",
    "        Returns:\n",
    "            Number of chunks created.\n",
    "        \"\"\"\n",
    "        if doc_id is None:\n",
    "            doc_id = os.path.basename(file_path)\n",
    "\n",
    "        text = read_pdf(file_path)\n",
    "\n",
    "        return self.index_document(text=text, doc_id=doc_id)\n",
    "\n",
    "    def index_text_file(self, file_path:str, doc_id:Optional[str]=None)->int:\n",
    "        \"\"\"\n",
    "        Read a text file and index its contents.\n",
    "\n",
    "        Args:\n",
    "            file_path:  Path to text file.\n",
    "            doc_id:     Document ID (defaults to filename).\n",
    "\n",
    "        Returns:\n",
    "            Number of chunks created.\n",
    "        \"\"\"\n",
    "\n",
    "        if doc_id is None:\n",
    "            doc_id = os.path.basename(file_path)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        return self.index_document(text=text, doc_id=doc_id)\n",
    "\n",
    "    def _merge_chunks_with_overlap_removal(self, chunks:List[str])->str:\n",
    "        \"\"\"\n",
    "        Concatenate neighboring chunks, trimming overlapping text.\n",
    "\n",
    "        When chunks were created with overlap, adjacent chunks share\n",
    "        `chunk_overlap` characters. This method removes that duplication\n",
    "        so the merged text reads naturally.\n",
    "\n",
    "        Example with chunk_overlap=200:\n",
    "            Chunk A: [AAAAAAA|BBBBB]     ‚Üê last 200 chars = \"BBBBB\"\n",
    "            Chunk B: [BBBBB|CCCCCCC]     ‚Üê first ~200 chars = \"BBBBB\"\n",
    "            \n",
    "            Merged:  [AAAAAAA|BBBBB|CCCCCCC]   ‚Üê overlap trimmed from A's tail\n",
    "\n",
    "        Args:\n",
    "            chunks:  Ordered list of chunk texts to merge.\n",
    "\n",
    "        Returns:\n",
    "            Merged text with overlaps removed.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not chunks:\n",
    "            return \"\"\n",
    "\n",
    "        merged = chunks[0]\n",
    "\n",
    "        for i in range(1, len(chunks)):\n",
    "\n",
    "            current_chunk = chunks[i]\n",
    "\n",
    "            if self.chunk_overlap > 0:\n",
    "                trim_point = max(0, len(merged) - self.chunk_overlap)\n",
    "                merged = merged[:trim_point] + current_chunk\n",
    "\n",
    "            else:\n",
    "                merged = merger + \"\\n\" + current_chunk\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def retrieve_standard(self, query:str) -> List[str]:\n",
    "        query_emb = self.embedder.embed_text(query)\n",
    "        results = self.vector_store.search(query_emb, k=self.k)\n",
    "        return [r.document.content for r in results]\n",
    "\n",
    "    def retrieve_with_context_window(self, query:str)->List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve chunks and expand each with neighboring chunks.\n",
    "\n",
    "        This is the core method. For each vector search hit:\n",
    "            1. Get the chunk's position index from metadata\n",
    "            2. Fetch ¬±num_neighbors chunks from ChunkStore (O(1) each)\n",
    "            3. Merge them with overlap removal\n",
    "            4. Return the expanded text\n",
    "\n",
    "        Args:\n",
    "            query:  Search query.\n",
    "\n",
    "        Returns:\n",
    "            List of expanded context strings (one per search hit).\n",
    "        \"\"\"\n",
    "\n",
    "        query_emb = self.embedder.embed_text(query)\n",
    "        results = self.vector_store.search(query_emb, k=self.k)\n",
    "\n",
    "        expanded_contexts = []\n",
    "        seen_ranges = set()\n",
    "\n",
    "        for result in results:\n",
    "            chunk_index = result.document.metadata.get(\"chunk_index\")\n",
    "\n",
    "            if chunk_index is None:\n",
    "                expanded_contexts.append(result.document.content)\n",
    "                continue \n",
    "\n",
    "            start = max(0, chunk_index - self.num_neighbors)\n",
    "\n",
    "            end = min(\n",
    "                self.chunk_store.total_chunks,\n",
    "                chunk_index + self.num_neighbors + 1\n",
    "            )\n",
    "\n",
    "            range_key = (start, end)\n",
    "\n",
    "            if range_key in seen_ranges:\n",
    "                continue\n",
    "\n",
    "            seen_ranges.add(range_key)\n",
    "\n",
    "            window_chunks = self.chunk_store.get_window(\n",
    "                center=chunk_index, \n",
    "                num_neighbors=self.num_neighbors\n",
    "            )\n",
    "\n",
    "\n",
    "            merged_text = self._merge_chunks_with_overlap_removal(window_chunks)\n",
    "            expanded_contexts.append(merged_text)\n",
    "\n",
    "        return expanded_contexts\n",
    "    \n",
    "    def compare_retrieval(self, query:str)->List[str]:\n",
    "        standard = self.retrieve_standard(query)\n",
    "        context_window = self.retrieve_with_context_window(query)\n",
    "        return {\n",
    "            \"standard\": standard,\n",
    "            \"context_window\": context_window\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d988c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEnrichmentRAG:\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        chunk_size: int = 400,\n",
    "        chunk_overlap: int = 200,\n",
    "        num_neighbors: int = 1,\n",
    "        k: int = 3,\n",
    "        embedding_model: str = \"text-embedding-3-small\",\n",
    "        chat_model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.0,\n",
    "    ):\n",
    "\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.retriever = ContextEnrichmentRetriever(\n",
    "            embedding_model=embedding_model,\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            num_neighbors=num_neighbors,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        self.chat = OpenAIChat(\n",
    "            model_name=chat_model,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            num_chunks = self.retriever.index_pdf(file_path=file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            num_chunks = self.retriever.index_text_file(file_path=file_path)\n",
    "        \n",
    "\n",
    "    def query(self, question:str, return_context:bool=True)->str:\n",
    "        \"\"\"\n",
    "        Query the RAG system with context-enriched retrieval.\n",
    "\n",
    "        Args:\n",
    "            question:        User's question.\n",
    "            return_context:  Whether to return the expanded contexts.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (answer_string, list_of_context_strings).\n",
    "        \"\"\"\n",
    "        contexts = self.retriever.retrieve_with_context_window(question)\n",
    "\n",
    "        if not contexts:\n",
    "            return \"No relevant information found in the document.\", []\n",
    "\n",
    "        answer = self.chat.chat_with_context(question, contexts)\n",
    "\n",
    "        if return_context:\n",
    "            return answer, contexts\n",
    "        return answer, []\n",
    "\n",
    "    def compare(self, question:str)->None:\n",
    "        \"\"\"\n",
    "        Compare standard VS enriched retrieval side by side.\n",
    "\n",
    "        Args:\n",
    "            question: search query\n",
    "        \"\"\" \n",
    "\n",
    "        comparison = self.retriever.compare_retrieval(question)\n",
    "        \n",
    "        print(f\"\\nQuery: {question}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        print(\"\\nüì¶ STANDARD RETRIEVAL (isolated chunks):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, ctx in enumerate(comparison[\"standard\"]):\n",
    "            print(f\"\\n  Chunk {i + 1} ({len(ctx)} chars):\")\n",
    "            print(f\"    {ctx[:200]}...\")\n",
    "\n",
    "        print(f\"\\nüîç ENRICHED RETRIEVAL (with ¬±{self.retriever.num_neighbors} neighbors):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, ctx in enumerate(comparison[\"context_window\"]):\n",
    "            print(f\"\\n  Window {i + 1} ({len(ctx)} chars):\")\n",
    "            print(f\"    {ctx[:300]}...\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4548c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\TempAccess\\\\Documents\\\\Dhruv\\\\RAG\\\\data\\\\Understanding_Climate_Change.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_pdf_path = r\"C:\\Users\\TempAccess\\Documents\\Dhruv\\RAG\\data\\Understanding_Climate_Change.pdf\"\n",
    "rag_pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edf41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG = ContextEnrichmentRAG(\n",
    "    file_path=rag_pdf_path,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    num_neighbors=1,\n",
    "    k=3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c94f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is climate change?\n",
      "======================================================================\n",
      "\n",
      "üì¶ STANDARD RETRIEVAL (isolated chunks):\n",
      "--------------------------------------------------\n",
      "\n",
      "  Chunk 1 (947 chars):\n",
      "    Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the plane...\n",
      "\n",
      "  Chunk 2 (1195 chars):\n",
      "    man civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which ...\n",
      "\n",
      "  Chunk 3 (1178 chars):\n",
      "    igate these emissions. The \n",
      "development of eco-friendly fertilizers and farming techniques is essential for reducing the \n",
      "agricultural sector's carbon footprint. \n",
      "Chapter 3: Effects of Climate Change ...\n",
      "\n",
      "üîç ENRICHED RETRIEVAL (with ¬±1 neighbors):\n",
      "--------------------------------------------------\n",
      "\n",
      "  Window 1 (1942 chars):\n",
      "    Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an exte...\n",
      "\n",
      "  Window 2 (2882 chars):\n",
      "    Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an exte...\n",
      "\n",
      "  Window 3 (3004 chars):\n",
      "    tock, rice \n",
      "paddies, and the use of synthetic fertilizers. Methane is a potent greenhouse gas with a much \n",
      "higher heat-trapping capability than CO2, albeit in smaller quantities. \n",
      "Livestock Emissions Ruminant animals, such as cows and sheep, produce methane during digestion. Manure \n",
      "management pract...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is climate change?\"\n",
    "\n",
    "answer = RAG.compare(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f24597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
